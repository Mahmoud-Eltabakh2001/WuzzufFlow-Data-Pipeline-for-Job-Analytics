def validate_data():
    from pyspark.sql import SparkSession
    import great_expectations as gx
    from great_expectations.dataset import SparkDFDataset
    from great_expectations.render.renderer import ValidationResultsPageRenderer
    from great_expectations.render.view import DefaultJinjaPageView
    import os

    # ğŸš€ ØªØ´ØºÙŠÙ„ Spark
    spark = SparkSession.builder.appName("Validation").getOrCreate()

    # ğŸ“¥ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† HDFS
    df = spark.read.option("header", True).csv("hdfs://namenode:8020/wuzzuf_output/Wuzzuf_data_transformed")

    # âœ… Great Expectations Ø§Ù„ØªØ­Ù‚Ù‚ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù…
    ge_df = SparkDFDataset(df)
    ge_df._initialize_expectations(expectation_suite_name="scraping_suite")
    ge_df.expect_column_values_to_not_be_null("id")
    ge_df.expect_column_values_to_be_unique("id")
    ge_df.expect_column_values_to_not_be_null("job_title")
    ge_df.expect_column_values_to_not_be_null("company_name")
    results = ge_df.validate()

    # ğŸ“ ÙƒØªØ§Ø¨Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ± ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù„ÙŠ Ù…Ø¹Ù…ÙˆÙ„ Ù„Ù‡ mount
    #report_path = "/opt/airflow/validation_report/validation_report.html"
    report_path = "/opt/bitnami/spark/validation_report/validation_report.html"


    os.makedirs(os.path.dirname(report_path), exist_ok=True)

    document_model = ValidationResultsPageRenderer().render(results)
    html_report = DefaultJinjaPageView().render(document_model)

    with open(report_path, "w", encoding="utf-8") as f:
        f.write(html_report)
